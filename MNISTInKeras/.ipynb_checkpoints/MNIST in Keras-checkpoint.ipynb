{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why neural networks?\n",
    "\n",
    "- Good for image classification and facial recognition \n",
    "- Use of multiple layers allows the network to first find shapes and arc, then find objects like a nose, eyes, mouth, then finally recognize a whole face\n",
    "\n",
    "![title](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-10-at-12-58-30-pm.png?w=484&h=510)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Implementation (NN, Regression, etc)\n",
    "\n",
    "1. Prepare/clean the data for input\n",
    "2. Build/train model to make a the prediction\n",
    "3. Determine how to measure the loss\n",
    "4. Optimize to update the parameters to minimize loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do NN's work?\n",
    "\n",
    "Using neuron architecture\n",
    "\n",
    "1. Inputs are multiplied by weights and added to the bias as inputs to the next layer \n",
    "2. Outputs use an activation function and give the output (forward propagation)\n",
    "3. Compute loss\n",
    "4. Reassign weights and biases\n",
    "\n",
    "![title](https://cdn-images-1.medium.com/max/1600/1*QVIyc5HnGDWTNX3m-nIm9w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs\n",
    "\n",
    "Has technical degree and hours spent per day studying ML\n",
    "\n",
    "`X = [\n",
    "        [0, 3.5], #person 1\n",
    "        [1, 2],   #person 2\n",
    "        [1, 0.5]  #person 3\n",
    "    ]\n",
    "`\n",
    "\n",
    "Shape = 3 x 2 \n",
    "\n",
    "#### Hidden layer? \n",
    "\n",
    "Selection for of this number is too advanced\n",
    "We'll assume 3 for now\n",
    "\n",
    "#### Output\n",
    "\n",
    "Will this person succeed at ML?  Yes or no? (binary classification)\n",
    "\n",
    "`Y = [\n",
    "        1, #labeled target for person 1\n",
    "        1, #labeled target for person 2\n",
    "        0  #labeled target for person 3\n",
    "    ]\n",
    "`\n",
    "\n",
    "Where 1 = yes and 0 = no\n",
    "\n",
    "The target is supplied so the NN knows what to train against\n",
    "\n",
    "Shape = 3 x 2\n",
    "Why not 3x1?  Because we actually have 2 classifications here, will succeed and will not succeed.  So we really want our final matrix to look like this by using 2 output neurons:\n",
    "\n",
    "`Y = [\n",
    "        [0, 1], # a 1 in the success column\n",
    "        [0, 1], # a 1 in the success column\n",
    "        [1, 0]  # a 1 in the no success column\n",
    "    ]\n",
    "`\n",
    "\n",
    "And acutally... we won't get straight 0s and 1s, we'll get probabilities for each classification that then pass through the activation function to turn into predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights \n",
    "Thought of as the 'importance' of an input, can be randomly assigned at first\n",
    "\n",
    "`W = [\n",
    "        [0.5, 0.1, -0.3], #w11, w12, w13\n",
    "        [0.7, -0.3, 0.2]  #w21, w22, w23\n",
    "    ]\n",
    "`\n",
    "\n",
    "Shape = 2 x 3 \n",
    "\n",
    "#### Bias \n",
    "Thought of as the 'threshold' thus makes outputs binary\n",
    "\n",
    "`b = [\n",
    "        0.4  #b1\n",
    "        0.1, #b2\n",
    "        0    #b3\n",
    "    ]\n",
    "`\n",
    "\n",
    "Shape = 3 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication anyone?\n",
    "\n",
    "`\n",
    "z1 = (0 * 0.5) + (3.5 * 0.7) + 0.4 = 2.85\n",
    "z2 = (0 * 0.1) + (3.5 * -0.3) + 0.1 = -0.95\n",
    "z3 = (0 * -0.3) + (3.5 * 0.2) + 0 = 0.7\n",
    "`\n",
    "\n",
    "So:\n",
    "X is 1x2, W is 2x3, we get a 1x3 matrix. (M x D * D x N = M x N)\n",
    "\n",
    "`Z = [\n",
    "    2.85,\n",
    "    -0.95\n",
    "    0.7\n",
    "]`\n",
    "\n",
    "But really, these are passed through the activation function first.  This example uses the tanh function which gives us...\n",
    "\n",
    "`Z = [\n",
    "    0.993,\n",
    "    -0.74,\n",
    "    0.604\n",
    "]`\n",
    "\n",
    "For a SINGLE example\n",
    "But we have 3 data points... we can still use matrix multiplication\n",
    "X is 3x2, W is 2x3, we get a 3x3 matrix of all the Z values.\n",
    "\n",
    "`Z = XTW` (where T means transpose)\n",
    "\n",
    "If we follow the math forward\n",
    "Z is 3x3 and the new weights are 3x2 and the bias 3x1.\n",
    "\n",
    "`Y = ZTW` (3x3 * 3x2 = 3x2 output matrix)\n",
    "\n",
    "`\n",
    "y = [\n",
    "    [0.01, 0.99],\n",
    "    [0.02, 0.98],\n",
    "    [0.99, 0.01]\n",
    "]\n",
    "`\n",
    "\n",
    "Matching our training targets of:\n",
    "\n",
    "`Y = [\n",
    "        1,\n",
    "        1,\n",
    "        0\n",
    "    ]\n",
    "`\n",
    "\n",
    "Vectorized inputs are highly performant when using specialized libraries like numpy\n",
    "\n",
    "`y = (tanh(XW + b)V + c)` \n",
    "where \n",
    "- tanh is the activation function \n",
    "- V is the hidden layer weights vector \n",
    "- c is the bias for the final output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function\n",
    "Creates binary outputs (the predictions)\n",
    "\n",
    "Kind of more than you want to know about the different types of activation functions:\n",
    "https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n",
    "\n",
    "![title](https://cdn-images-1.medium.com/max/1600/1*UzqjTkSHgkrU55P71NKNMA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring loss and reassigning weights and biases\n",
    "\n",
    "An example of one way to measure loss is with gradient descent on a regression problem\n",
    "\n",
    "![title](https://www.neural-networks.io/images/single-layer/gradient-overview.png)\n",
    "\n",
    "Using a bunch of calculus... \n",
    "\n",
    "(See Andrew NG's ML Intro Course on Coursera for 11 weeks of math fun: https://www.coursera.org/learn/machine-learning)\n",
    "\n",
    "... the gradient descent equation minimizes loss through steps.  \n",
    "\n",
    "Each step recalculates the appropriate weights and biases in order to minimize loss.\n",
    "\n",
    "Then pass through the network again.\n",
    "\n",
    "The more steps, the more we minimize the loss.\n",
    "\n",
    "However, the above curve is an oversimplified version.  Real ML problems have many features and dimensions.\n",
    "\n",
    "![title](https://cdn-images-1.medium.com/max/1600/1*09kq2L23D9XM_9Xtr8gc8Q.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression line fitting in action\n",
    "\n",
    "![title](https://cdn-images-1.medium.com/max/1600/1*eeIvlwkMNG1wSmj3FR6M2g.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is NIST?\n",
    "\n",
    "National Institue of Standards and Technologies\n",
    "- Classic set to often compare performances of different models\n",
    "- 70k data points = 55k training, 10k test, 5k validation, 28x28 handwritten greyscale images, labels 0-9\n",
    "- Used for the 'hello world' examples of machine learning\n",
    "\n",
    "![title](https://www.researchgate.net/profile/Steven_Young11/publication/306056875/figure/fig1/AS:393921575309346@1470929630835/Example-images-from-the-MNIST-dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Implementation (refresher) \n",
    "\n",
    "1. Prepare/clean the data\n",
    "2. Build/train model to make a the prediction\n",
    "3. Determine how to measure the loss\n",
    "4. Optimize to update the parameters to minimize loss\n",
    "\n",
    "## MNIST Implementation\n",
    "\n",
    "1. Load the MNIST Data \n",
    "2. Combine image data values with NNs weights and biases, then run through an activation function to produce a result\n",
    "3. Have a measurement method to determine loss\n",
    "4. Use an optimizer to update params and reduce loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Keras?\n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "Use Keras if you need a deep learning library that:\n",
    "\n",
    "- Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
    "- Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
    "- Runs seamlessly on CPU and GPU.\n",
    "\n",
    "https://keras.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import coremltools\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of samples used in one training iteration\n",
    "batch_size = 128\n",
    "\n",
    "#number of times we want to train over the entire data set\n",
    "epochs = 10\n",
    "\n",
    "#we have numbers 0-9, so 10 classes\n",
    "num_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_x, img_y = 28, 28\n",
    "\n",
    "# load the MNIST data set baked into Keras \n",
    "# it easily splits into train and test sets for us (usually around 80 - 20)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use pandas to load data\n",
    "`mnist = pd.read_csv('../input/data.csv')`\n",
    "\n",
    "And sklearn to split into train/test\n",
    "`from sklearn.model_selection import train_test_split`\n",
    "`x_train, x_test = train_test_split(mnist, test_size=0.2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28)\n",
      "60000 training samples\n",
      "x_test shape:  (10000, 28, 28)\n",
      "10000 validation samples\n"
     ]
    }
   ],
   "source": [
    "# Inspect x data\n",
    "print('x_train shape: ', x_train.shape)\n",
    "\n",
    "print(x_train.shape[0], 'training samples')\n",
    "\n",
    "print('x_test shape: ', x_test.shape)\n",
    "\n",
    "print(x_test.shape[0], 'validation samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First x sample\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print('First x sample\\n', x_train[0])\n",
    "# Displays an array of 28 arrays, each containing 28 gray-scale values between 0 and 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot first x sample\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now x_train is a 3D tensor - (sample_number, x_img_size, y_img_size)\n",
    "We need to reshape the data into a 4D tensor - (sample_number, x_img_size, y_img_size, num_channels)\n",
    "Because the MNIST is greyscale, we only have a single channel - RGB colour images would have 3\n",
    "In this case, we are supplying as channels-last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_x, img_y, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_x, img_y, 1)\n",
    "\n",
    "#a single inputs shape includes the channels\n",
    "input_shape = (img_x, img_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape:  (60000,)\n",
      "First 10 y_train elements: [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# Inspect y data\n",
    "print('y_train shape: ', y_train.shape)\n",
    "# Indicates we have 60000 labels ready to go\n",
    "\n",
    "print('First 10 y_train elements:', y_train[:10])\n",
    "# Displays [5 0 4 1 9 2 1 3 1 4] a small sample of our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "# this is for use in the categorical_crossentropy loss below\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now we've said we have 10 classes and we have labels 0-9, but we might as well have used colors\n",
    "In this context 0-9 are not numbers, they are categories, and ML can't process literal categories\n",
    "So all 60000 labels are converted into a binary matrix like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape:  (60000, 10)\n",
      "First 10 y_train elements: [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Inspect y data\n",
    "print('y_train shape: ', y_train.shape)\n",
    "\n",
    "print('First 10 y_train elements:', y_train[:10])\n",
    "# Displays a binary matrix indicating the classification of each label category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# normalization of values to 0-1 generally improves efficiency and learning due to weights multiplication\n",
    "\n",
    "# they were in UInt8 with range 0-255 but now converting to float 32 with range 0-1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# then normalize\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First x sample, normalized\n",
      " [[[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01176471]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.49411765]\n",
      "  [0.53333336]\n",
      "  [0.6862745 ]\n",
      "  [0.10196079]\n",
      "  [0.6509804 ]\n",
      "  [1.        ]\n",
      "  [0.96862745]\n",
      "  [0.49803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.11764706]\n",
      "  [0.14117648]\n",
      "  [0.36862746]\n",
      "  [0.6039216 ]\n",
      "  [0.6666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.88235295]\n",
      "  [0.6745098 ]\n",
      "  [0.99215686]\n",
      "  [0.9490196 ]\n",
      "  [0.7647059 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.19215687]\n",
      "  [0.93333334]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.9843137 ]\n",
      "  [0.3647059 ]\n",
      "  [0.32156864]\n",
      "  [0.32156864]\n",
      "  [0.21960784]\n",
      "  [0.15294118]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.7137255 ]\n",
      "  [0.96862745]\n",
      "  [0.94509804]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.3137255 ]\n",
      "  [0.6117647 ]\n",
      "  [0.41960785]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8039216 ]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.16862746]\n",
      "  [0.6039216 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.05490196]\n",
      "  [0.00392157]\n",
      "  [0.6039216 ]\n",
      "  [0.99215686]\n",
      "  [0.3529412 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.54509807]\n",
      "  [0.99215686]\n",
      "  [0.74509805]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.04313726]\n",
      "  [0.74509805]\n",
      "  [0.99215686]\n",
      "  [0.27450982]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.13725491]\n",
      "  [0.94509804]\n",
      "  [0.88235295]\n",
      "  [0.627451  ]\n",
      "  [0.42352942]\n",
      "  [0.00392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.31764707]\n",
      "  [0.9411765 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.46666667]\n",
      "  [0.09803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.1764706 ]\n",
      "  [0.7294118 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.5882353 ]\n",
      "  [0.10588235]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.0627451 ]\n",
      "  [0.3647059 ]\n",
      "  [0.9882353 ]\n",
      "  [0.99215686]\n",
      "  [0.73333335]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9764706 ]\n",
      "  [0.99215686]\n",
      "  [0.9764706 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.18039216]\n",
      "  [0.50980395]\n",
      "  [0.7176471 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8117647 ]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.15294118]\n",
      "  [0.5803922 ]\n",
      "  [0.8980392 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.98039216]\n",
      "  [0.7137255 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09411765]\n",
      "  [0.44705883]\n",
      "  [0.8666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7882353 ]\n",
      "  [0.30588236]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09019608]\n",
      "  [0.25882354]\n",
      "  [0.8352941 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.31764707]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.67058825]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7647059 ]\n",
      "  [0.3137255 ]\n",
      "  [0.03529412]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.21568628]\n",
      "  [0.6745098 ]\n",
      "  [0.8862745 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.95686275]\n",
      "  [0.52156866]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.53333336]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.83137256]\n",
      "  [0.5294118 ]\n",
      "  [0.5176471 ]\n",
      "  [0.0627451 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "#print the normalized data\n",
    "print('First x sample, normalized\\n', x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two forms of Keras models, sequential or functional API\n",
    "**Sequential** is common for deep leaning networks\n",
    "\n",
    "Easily stacks sequential layers of the network in order from input to output\n",
    "**Functional API** allows you to build more complex architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll go with sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional what?\n",
    "\n",
    "Convolution neural networks\n",
    "\n",
    "In short, CNNs are better at image classification because the layers do a good job at discovering features, both important and non-important, later filtering their importance, and hierarchically stacking features into more complex features. (lines help predict a nose which helps predicts a face)\n",
    "\n",
    "CNNs are great at finding patterns\n",
    "\n",
    "We will only very briefly cover some of the layers in a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first layer\n",
    "\n",
    "**32** = the number of features to detect, also the number of output channels\n",
    "\n",
    "**kernel_size** = a 5x5 moving window that computes weighted sums\n",
    "\n",
    "**strides** = strides in the x and y directions\n",
    "\n",
    "**relu** = rectified linear unit our activation function to determine whether or not a given unit will 'fire'/activate\n",
    "\n",
    "**input_shape** = size of the input layer\n",
    "\n",
    "We didn't have to declare any weights or bias! (though you do in TensorFlow, bleh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so, this is actually a convolutional neural network, which does not work quite the same as out intro example\n",
    "#but we will discuss CNNs in a follow up talk\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=(5, 5), \n",
    "                 strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the size of the pooling in the x and y directions and the stride\n",
    "#max pooling refilters to pool only maximum values\n",
    "#thus reduces the number of parameters and helps with overfitting\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://koenig-media.raywenderlich.com/uploads/2017/12/pool.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#often paired with a pooling layer\n",
    "#randomly sets a fraction of input units to 0 to control overfitting\n",
    "#means neurons are less influenced by neighboring neurons becuase they might drop out of the network at random\n",
    "#makes network less sensitive to small variations in input, so is more likely to generalize new inputs\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#64 output channels\n",
    "#strides parameter is left out because we want the default of 1, 1\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we leave strides out of here because default is to make it same as pool size\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#the input tensor for this later is (batch_size, 28, 28) because 28x28 is the size of the image\n",
    "#we don't have to explicitly set the shape, Keras will figure it out, for rapid assembly of network architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(128, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that all layers are built, flatten the output\n",
    "#we don't have to figure out size of output tensor in order to flatten like in TF\n",
    "#flattened into 1 dimensional layer before passing to the fully connected dense layer\n",
    "#the output shape of the previous layer is (2, 2, 128) so output of flatten has 512 elements\n",
    "model.add(Flatten())\n",
    "\n",
    "#our fully connected layers\n",
    "#specify size of 128 nodes, each activated by a ReLU function\n",
    "#each layer only uses values of a few neurons in the previous layer\n",
    "#fully connected layer uses all values of neurons in previous layer (Dense layer)\n",
    "#this is key in how long a network might take to compute if it has a large number of neurons in a fully connected layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "#our output layer, a softmax classification\n",
    "#softmax is a generalization of sigmoid which scaled the input value into the range 0 to 1\n",
    "#softmax scales each of 10 values into 0 to 1, adding up to 1\n",
    "#which is the size of the number of classes - 10\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 128)         8320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 94,602\n",
      "Trainable params: 94,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#show a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://koenig-media.raywenderlich.com/uploads/2017/12/dense.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the loss function\n",
    "#tell the framework which type of optimizer to use\n",
    "#use standard crossentropy for loss and adam for optimizer\n",
    "#add the accuracy metric to be called when we run evaluate()\n",
    "#in TF we have to define the accuracy calculating operation\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup a class based on keras.callbacks.Callback\n",
    "#includes delegate methods like on_train_begin, which are self explanatory\n",
    "#and are called during the training process\n",
    "#in this case, we are appending the accuracy to an array at the end of each epoch\n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        \n",
    "history = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add some callbacks for saving and to stop if acc goes down two epochs in a row\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='acc', patience=1),\n",
    "    history\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Pass all our training data, x_train and y_train\n",
    "\n",
    "**batch_size** = we don't have to explicitly handle batching, just pass the size (128 in our case)\n",
    "\n",
    "**epochs** = 10, since we batch, an epoch indicates a pass through of all batches\n",
    "\n",
    "**verbose** = print detailed info during training\n",
    "\n",
    "**validation_data** = pass the test sets as the validation data so Keras knows what to target\n",
    "\n",
    "**callbacks** - our checkpoitn creator, our early stop monitor, and our accuracy history printout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 52s 869us/step - loss: 0.4905 - acc: 0.8407 - val_loss: 0.1163 - val_acc: 0.9663\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 44s 727us/step - loss: 0.1606 - acc: 0.9500 - val_loss: 0.0706 - val_acc: 0.9792\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 47s 780us/step - loss: 0.1213 - acc: 0.9625 - val_loss: 0.0502 - val_acc: 0.9855\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 48s 794us/step - loss: 0.0975 - acc: 0.9695 - val_loss: 0.0427 - val_acc: 0.9879\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 43s 723us/step - loss: 0.0866 - acc: 0.9730 - val_loss: 0.0397 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 44s 729us/step - loss: 0.0761 - acc: 0.9759 - val_loss: 0.0400 - val_acc: 0.9879\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 47s 778us/step - loss: 0.0686 - acc: 0.9777 - val_loss: 0.0346 - val_acc: 0.9885\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 45s 745us/step - loss: 0.0641 - acc: 0.9799 - val_loss: 0.0309 - val_acc: 0.9896\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 44s 725us/step - loss: 0.0593 - acc: 0.9809 - val_loss: 0.0295 - val_acc: 0.9898\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 45s 742us/step - loss: 0.0554 - acc: 0.9822 - val_loss: 0.0293 - val_acc: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa2af21048>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.02926507827178575\n",
      "Test accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model and print the results\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#access the history of accuracy and plot it for visulization\n",
    "plt.plot(range(1, 11), history.acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# For the first argument, use the filename of the newest .h5 file in the notebook folder.\n",
    "coreml_mnist = coremltools.converters.keras.convert('best_model.10-0.03.h5', input_names=['image'], output_names=['output'], class_labels=output_labels, image_input_names='image')\n",
    "print(coreml_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a SavedModel.\n",
    "# converter = lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "# tflite_model = converter.convert()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add xcode metadata\n",
    "coreml_mnist.author = 'Frankie'\n",
    "coreml_mnist.license = 'MIT'\n",
    "coreml_mnist.short_description = 'Image based digit recognition (MNIST)'\n",
    "coreml_mnist.input_description['image'] = 'Digit image'\n",
    "coreml_mnist.output_description['output'] = 'Probability of each digit'\n",
    "coreml_mnist.output_description['classLabel'] = 'Labels of digits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it!\n",
    "coreml_mnist.save('MNISTClassifier.mlmodel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
